docker-compose up --build

W pgadmin zrobić insert do "eduational_data"

zobaczyć zmianę w data_source.public.educational_data

http://localhost:9000 -> kafkadrop




PIERWSZE KROKI JAKIE SIĘ ROBI PO POPRAWNYM ŚCIĄGNIĘCIU PROJEKTU:


- pierwszy raz:
docker compose up -d --build     # pierwszy raz


INSERT INTO:

SELECT * FROM educational_data;
INSERT INTO "educational_data"
    ("Full Name",
     "Age",
     "Education Level",
     "Major",
     "Year Started Education",
     "Year Completed Education",
     "Type of Educational Institution",
     "Average Grade")
VALUES
    ('John DoeAAAAAAA',
     22,
     'Tertiary',
     'Computer Science',
     2018,
     2022,
     'Public',
     3.5);











     # build & (if spark not yet running) start the stack
docker compose up -d --build


docker compose exec spark spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-avro_2.12:3.5.0 /opt/spark-jobs/kafka_avro_transform.py